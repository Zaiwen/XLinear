Args in experiment:
Namespace(random_seed=2025, is_training=1, model_id='ETTh1_96_192', model='MLPAer_only_channel', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, fc_dropout=0.05, head_dropout=0.6, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=100, learning_rate=0.0002, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, c_ff=14, t_ff=512, c_dropout=0.0, t_dropout=0.2, embed_dropout=0.0, head_type='prediction', usenorm=1, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_96_192_MLPAer_only_channel_ETTh1_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
Epoch: 1 cost time: 1.2432608604431152
Epoch: 1, Steps: 65 | Train Loss: 0.6113148 Vali Loss: 1.4154131 Test Loss: 0.7224640
Validation loss decreased (inf --> 1.415413).  Saving model ...
Updating learning rate to 0.0002
Epoch: 2 cost time: 0.991553544998169
Epoch: 2, Steps: 65 | Train Loss: 0.5494212 Vali Loss: 1.1415638 Test Loss: 0.5199206
Validation loss decreased (1.415413 --> 1.141564).  Saving model ...
Updating learning rate to 0.0002
Epoch: 3 cost time: 0.9480471611022949
Epoch: 3, Steps: 65 | Train Loss: 0.4830328 Vali Loss: 1.0860695 Test Loss: 0.4935646
Validation loss decreased (1.141564 --> 1.086069).  Saving model ...
Updating learning rate to 0.0002
Epoch: 4 cost time: 0.9967179298400879
Epoch: 4, Steps: 65 | Train Loss: 0.4630571 Vali Loss: 1.0367323 Test Loss: 0.4578326
Validation loss decreased (1.086069 --> 1.036732).  Saving model ...
Updating learning rate to 0.00018
Epoch: 5 cost time: 1.0097675323486328
Epoch: 5, Steps: 65 | Train Loss: 0.4485047 Vali Loss: 1.0180665 Test Loss: 0.4468686
Validation loss decreased (1.036732 --> 1.018067).  Saving model ...
Updating learning rate to 0.000162
Epoch: 6 cost time: 1.07468581199646
Epoch: 6, Steps: 65 | Train Loss: 0.4427853 Vali Loss: 1.0110848 Test Loss: 0.4438341
Validation loss decreased (1.018067 --> 1.011085).  Saving model ...
Updating learning rate to 0.00014580000000000002
Epoch: 7 cost time: 1.0756702423095703
Epoch: 7, Steps: 65 | Train Loss: 0.4393719 Vali Loss: 1.0071790 Test Loss: 0.4418323
Validation loss decreased (1.011085 --> 1.007179).  Saving model ...
Updating learning rate to 0.00013122
Epoch: 8 cost time: 1.147460699081421
Epoch: 8, Steps: 65 | Train Loss: 0.4373048 Vali Loss: 1.0056485 Test Loss: 0.4402724
Validation loss decreased (1.007179 --> 1.005648).  Saving model ...
Updating learning rate to 0.00011809800000000002
Epoch: 9 cost time: 0.9612889289855957
Epoch: 9, Steps: 65 | Train Loss: 0.4356720 Vali Loss: 1.0033054 Test Loss: 0.4394297
Validation loss decreased (1.005648 --> 1.003305).  Saving model ...
Updating learning rate to 0.00010628820000000001
Epoch: 10 cost time: 0.9328093528747559
Epoch: 10, Steps: 65 | Train Loss: 0.4341973 Vali Loss: 1.0024036 Test Loss: 0.4397889
Validation loss decreased (1.003305 --> 1.002404).  Saving model ...
Updating learning rate to 9.565938000000003e-05
Epoch: 11 cost time: 1.0450005531311035
Epoch: 11, Steps: 65 | Train Loss: 0.4329130 Vali Loss: 1.0024844 Test Loss: 0.4378875
EarlyStopping counter: 1 out of 100
Updating learning rate to 8.609344200000003e-05
Epoch: 12 cost time: 0.9895350933074951
Epoch: 12, Steps: 65 | Train Loss: 0.4326224 Vali Loss: 0.9986732 Test Loss: 0.4373101
Validation loss decreased (1.002404 --> 0.998673).  Saving model ...
Updating learning rate to 7.748409780000002e-05
Epoch: 13 cost time: 0.9424870014190674
Epoch: 13, Steps: 65 | Train Loss: 0.4314641 Vali Loss: 0.9979813 Test Loss: 0.4363329
Validation loss decreased (0.998673 --> 0.997981).  Saving model ...
Updating learning rate to 6.973568802000002e-05
Epoch: 14 cost time: 1.0487902164459229
Epoch: 14, Steps: 65 | Train Loss: 0.4308521 Vali Loss: 0.9976956 Test Loss: 0.4366169
Validation loss decreased (0.997981 --> 0.997696).  Saving model ...
Updating learning rate to 6.276211921800002e-05
Epoch: 15 cost time: 1.0280628204345703
Epoch: 15, Steps: 65 | Train Loss: 0.4301667 Vali Loss: 0.9968414 Test Loss: 0.4354112
Validation loss decreased (0.997696 --> 0.996841).  Saving model ...
Updating learning rate to 5.648590729620002e-05
Epoch: 16 cost time: 1.1665668487548828
Epoch: 16, Steps: 65 | Train Loss: 0.4292656 Vali Loss: 0.9960528 Test Loss: 0.4351115
Validation loss decreased (0.996841 --> 0.996053).  Saving model ...
Updating learning rate to 5.083731656658002e-05
Epoch: 17 cost time: 1.0601940155029297
Epoch: 17, Steps: 65 | Train Loss: 0.4294738 Vali Loss: 0.9957506 Test Loss: 0.4344130
Validation loss decreased (0.996053 --> 0.995751).  Saving model ...
Updating learning rate to 4.575358490992202e-05
Epoch: 18 cost time: 0.9743645191192627
Epoch: 18, Steps: 65 | Train Loss: 0.4288674 Vali Loss: 0.9950463 Test Loss: 0.4340246
Validation loss decreased (0.995751 --> 0.995046).  Saving model ...
Updating learning rate to 4.117822641892981e-05
Epoch: 19 cost time: 1.2423138618469238
Epoch: 19, Steps: 65 | Train Loss: 0.4285856 Vali Loss: 0.9937996 Test Loss: 0.4341936
Validation loss decreased (0.995046 --> 0.993800).  Saving model ...
Updating learning rate to 3.706040377703683e-05
Epoch: 20 cost time: 1.034494161605835
Epoch: 20, Steps: 65 | Train Loss: 0.4279571 Vali Loss: 0.9932780 Test Loss: 0.4340018
Validation loss decreased (0.993800 --> 0.993278).  Saving model ...
Updating learning rate to 3.3354363399333154e-05
Epoch: 21 cost time: 1.177957534790039
Epoch: 21, Steps: 65 | Train Loss: 0.4274782 Vali Loss: 0.9948002 Test Loss: 0.4335189
EarlyStopping counter: 1 out of 100
Updating learning rate to 3.0018927059399838e-05
Epoch: 22 cost time: 0.9694168567657471
Epoch: 22, Steps: 65 | Train Loss: 0.4278131 Vali Loss: 0.9944865 Test Loss: 0.4333231
EarlyStopping counter: 2 out of 100
Updating learning rate to 2.7017034353459858e-05
Epoch: 23 cost time: 0.986884593963623
Epoch: 23, Steps: 65 | Train Loss: 0.4272250 Vali Loss: 0.9932936 Test Loss: 0.4333576
EarlyStopping counter: 3 out of 100
Updating learning rate to 2.431533091811387e-05
Epoch: 24 cost time: 1.1237578392028809
Epoch: 24, Steps: 65 | Train Loss: 0.4270007 Vali Loss: 0.9932891 Test Loss: 0.4333057
EarlyStopping counter: 4 out of 100
Updating learning rate to 2.1883797826302484e-05
Epoch: 25 cost time: 0.9436671733856201
Epoch: 25, Steps: 65 | Train Loss: 0.4268760 Vali Loss: 0.9935360 Test Loss: 0.4335138
EarlyStopping counter: 5 out of 100
Updating learning rate to 1.9695418043672237e-05
Epoch: 26 cost time: 0.9549009799957275
Epoch: 26, Steps: 65 | Train Loss: 0.4265938 Vali Loss: 0.9930538 Test Loss: 0.4331165
Validation loss decreased (0.993278 --> 0.993054).  Saving model ...
Updating learning rate to 1.7725876239305016e-05
Epoch: 27 cost time: 1.0140562057495117
Epoch: 27, Steps: 65 | Train Loss: 0.4265318 Vali Loss: 0.9927884 Test Loss: 0.4329646
Validation loss decreased (0.993054 --> 0.992788).  Saving model ...
Updating learning rate to 1.595328861537451e-05
Epoch: 28 cost time: 0.9738237857818604
Epoch: 28, Steps: 65 | Train Loss: 0.4265096 Vali Loss: 0.9931630 Test Loss: 0.4329590
EarlyStopping counter: 1 out of 100
Updating learning rate to 1.4357959753837061e-05
Epoch: 29 cost time: 0.9447994232177734
Epoch: 29, Steps: 65 | Train Loss: 0.4261616 Vali Loss: 0.9925150 Test Loss: 0.4329618
Validation loss decreased (0.992788 --> 0.992515).  Saving model ...
Updating learning rate to 1.2922163778453355e-05
Epoch: 30 cost time: 0.9645490646362305
Epoch: 30, Steps: 65 | Train Loss: 0.4261694 Vali Loss: 0.9928020 Test Loss: 0.4328246
EarlyStopping counter: 1 out of 100
Updating learning rate to 1.1629947400608019e-05
>>>>>>>testing : ETTh1_96_192_MLPAer_only_channel_ETTh1_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.43296194076538086, mae:0.4313443899154663, rse:0.6248511672019958
