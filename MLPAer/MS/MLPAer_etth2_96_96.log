Args in experiment:
Namespace(random_seed=2025, is_training=1, model_id='ETTh1_96_96', model='MLPAer_univariate', data='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', features='MS', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, fc_dropout=0.05, head_dropout=0.7, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, c_ff=7, t_ff=512, c_dropout=0.1, t_dropout=0.3, embed_dropout=0.1, head_type='prediction', usenorm=1, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_96_96_MLPAer_univariate_ETTh2_ftMS_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
Epoch: 1 cost time: 5.004993438720703
Epoch: 1, Steps: 66 | Train Loss: 0.2970579 Vali Loss: 0.2571850 Test Loss: 0.2073854
Validation loss decreased (inf --> 0.257185).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 4.76625919342041
Epoch: 2, Steps: 66 | Train Loss: 0.2555558 Vali Loss: 0.2010400 Test Loss: 0.1411547
Validation loss decreased (0.257185 --> 0.201040).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 4.811619758605957
Epoch: 3, Steps: 66 | Train Loss: 0.2175272 Vali Loss: 0.1944130 Test Loss: 0.1343269
Validation loss decreased (0.201040 --> 0.194413).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 4.866943359375
Epoch: 4, Steps: 66 | Train Loss: 0.2074460 Vali Loss: 0.1897383 Test Loss: 0.1320773
Validation loss decreased (0.194413 --> 0.189738).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 4.776592016220093
Epoch: 5, Steps: 66 | Train Loss: 0.2017509 Vali Loss: 0.1889199 Test Loss: 0.1313825
Validation loss decreased (0.189738 --> 0.188920).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 4.671511650085449
Epoch: 6, Steps: 66 | Train Loss: 0.1984553 Vali Loss: 0.1885873 Test Loss: 0.1311106
Validation loss decreased (0.188920 --> 0.188587).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 4.83056902885437
Epoch: 7, Steps: 66 | Train Loss: 0.1953206 Vali Loss: 0.1887214 Test Loss: 0.1310541
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 4.791252136230469
Epoch: 8, Steps: 66 | Train Loss: 0.1932828 Vali Loss: 0.1893565 Test Loss: 0.1311268
EarlyStopping counter: 2 out of 3
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 4.76207709312439
Epoch: 9, Steps: 66 | Train Loss: 0.1917986 Vali Loss: 0.1883619 Test Loss: 0.1312472
Validation loss decreased (0.188587 --> 0.188362).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
