Args in experiment:
Namespace(random_seed=2025, is_training=1, model_id='ETTh1_96_336', model='MLPAer_univariate', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='MS', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, fc_dropout=0.05, head_dropout=0.7, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=3, learning_rate=0.0002, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, c_ff=14, t_ff=512, c_dropout=0.0, t_dropout=0.0, embed_dropout=0.1, head_type='prediction', usenorm=1, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_96_336_MLPAer_univariate_ETTh1_ftMS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
Epoch: 1 cost time: 3.706829786300659
Epoch: 1, Steps: 64 | Train Loss: 0.2507989 Vali Loss: 0.1488246 Test Loss: 0.1006376
Validation loss decreased (inf --> 0.148825).  Saving model ...
Updating learning rate to 0.0002
Epoch: 2 cost time: 3.3598122596740723
Epoch: 2, Steps: 64 | Train Loss: 0.2355073 Vali Loss: 0.1388377 Test Loss: 0.0943286
Validation loss decreased (0.148825 --> 0.138838).  Saving model ...
Updating learning rate to 0.0002
Epoch: 3 cost time: 3.347208023071289
Epoch: 3, Steps: 64 | Train Loss: 0.2218359 Vali Loss: 0.1318169 Test Loss: 0.0912575
Validation loss decreased (0.138838 --> 0.131817).  Saving model ...
Updating learning rate to 0.0002
Epoch: 4 cost time: 3.3881735801696777
Epoch: 4, Steps: 64 | Train Loss: 0.2135324 Vali Loss: 0.1280339 Test Loss: 0.0888006
Validation loss decreased (0.131817 --> 0.128034).  Saving model ...
Updating learning rate to 0.00018
Epoch: 5 cost time: 3.4142861366271973
Epoch: 5, Steps: 64 | Train Loss: 0.2091352 Vali Loss: 0.1252771 Test Loss: 0.0869686
Validation loss decreased (0.128034 --> 0.125277).  Saving model ...
Updating learning rate to 0.000162
Epoch: 6 cost time: 3.421699047088623
Epoch: 6, Steps: 64 | Train Loss: 0.2069561 Vali Loss: 0.1242112 Test Loss: 0.0865529
Validation loss decreased (0.125277 --> 0.124211).  Saving model ...
Updating learning rate to 0.00014580000000000002
Epoch: 7 cost time: 3.3878743648529053
Epoch: 7, Steps: 64 | Train Loss: 0.2059700 Vali Loss: 0.1252857 Test Loss: 0.0869239
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.00013122
Epoch: 8 cost time: 3.392670154571533
Epoch: 8, Steps: 64 | Train Loss: 0.2051138 Vali Loss: 0.1250104 Test Loss: 0.0868537
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.00011809800000000002
Epoch: 9 cost time: 3.3810837268829346
Epoch: 9, Steps: 64 | Train Loss: 0.2039124 Vali Loss: 0.1234528 Test Loss: 0.0860066
Validation loss decreased (0.124211 --> 0.123453).  Saving model ...
Updating learning rate to 0.00010628820000000001
Epoch: 10 cost time: 3.395052194595337
Epoch: 10, Steps: 64 | Train Loss: 0.2035764 Vali Loss: 0.1253571 Test Loss: 0.0866683
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.565938000000003e-05
Epoch: 11 cost time: 3.3639864921569824
Epoch: 11, Steps: 64 | Train Loss: 0.2024949 Vali Loss: 0.1259227 Test Loss: 0.0867229
EarlyStopping counter: 2 out of 3
Updating learning rate to 8.609344200000003e-05
Epoch: 12 cost time: 3.3719482421875
Epoch: 12, Steps: 64 | Train Loss: 0.2025669 Vali Loss: 0.1262216 Test Loss: 0.0870380
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_96_336_MLPAer_univariate_ETTh1_ftMS_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.08600662648677826, mae:0.22974717617034912, rse:0.8902727365493774
