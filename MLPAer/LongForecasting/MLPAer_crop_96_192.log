Args in experiment:
Namespace(random_seed=2025, is_training=1, model_id='crop_96_192', model='MLPAer', data='custom', root_path='./dataset/crop', data_path='crop.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, fc_dropout=0.05, head_dropout=0.4, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=8, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=100, learning_rate=0.001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, c_ff=8, t_ff=256, c_dropout=0.1, t_dropout=0.1, embed_dropout=0.1, head_type='prediction', usenorm=1, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : crop_96_192_MLPAer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5952
val 702
test 1591
Epoch: 1 cost time: 0.9647719860076904
Epoch: 1, Steps: 46 | Train Loss: 1.2016582 Vali Loss: 1.2611949 Test Loss: 0.7891796
Validation loss decreased (inf --> 1.261195).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.7392187118530273
Epoch: 2, Steps: 46 | Train Loss: 0.9436077 Vali Loss: 0.9308580 Test Loss: 0.6113344
Validation loss decreased (1.261195 --> 0.930858).  Saving model ...
Updating learning rate to 0.001
Epoch: 3 cost time: 0.7143590450286865
Epoch: 3, Steps: 46 | Train Loss: 0.8639313 Vali Loss: 0.9009600 Test Loss: 0.5932078
Validation loss decreased (0.930858 --> 0.900960).  Saving model ...
Updating learning rate to 0.001
Epoch: 4 cost time: 0.7347941398620605
Epoch: 4, Steps: 46 | Train Loss: 0.8504994 Vali Loss: 0.8988886 Test Loss: 0.5847924
Validation loss decreased (0.900960 --> 0.898889).  Saving model ...
Updating learning rate to 0.0009000000000000001
Epoch: 5 cost time: 0.7276980876922607
Epoch: 5, Steps: 46 | Train Loss: 0.8378594 Vali Loss: 0.8936070 Test Loss: 0.5725930
Validation loss decreased (0.898889 --> 0.893607).  Saving model ...
Updating learning rate to 0.0008100000000000001
Epoch: 6 cost time: 0.7533791065216064
Epoch: 6, Steps: 46 | Train Loss: 0.8256764 Vali Loss: 0.8890645 Test Loss: 0.5650781
Validation loss decreased (0.893607 --> 0.889064).  Saving model ...
Updating learning rate to 0.0007290000000000002
Epoch: 7 cost time: 0.8242783546447754
Epoch: 7, Steps: 46 | Train Loss: 0.8145555 Vali Loss: 0.8786972 Test Loss: 0.5533727
Validation loss decreased (0.889064 --> 0.878697).  Saving model ...
Updating learning rate to 0.0006561000000000001
Epoch: 8 cost time: 0.8139207363128662
Epoch: 8, Steps: 46 | Train Loss: 0.7944100 Vali Loss: 0.8589737 Test Loss: 0.5395120
Validation loss decreased (0.878697 --> 0.858974).  Saving model ...
Updating learning rate to 0.00059049
Epoch: 9 cost time: 0.8000266551971436
Epoch: 9, Steps: 46 | Train Loss: 0.7731593 Vali Loss: 0.8431919 Test Loss: 0.5356269
Validation loss decreased (0.858974 --> 0.843192).  Saving model ...
Updating learning rate to 0.000531441
Epoch: 10 cost time: 0.756899356842041
Epoch: 10, Steps: 46 | Train Loss: 0.7568386 Vali Loss: 0.8415266 Test Loss: 0.5328897
Validation loss decreased (0.843192 --> 0.841527).  Saving model ...
Updating learning rate to 0.0004782969000000001
Epoch: 11 cost time: 0.7144389152526855
Epoch: 11, Steps: 46 | Train Loss: 0.7412723 Vali Loss: 0.8300132 Test Loss: 0.5315357
Validation loss decreased (0.841527 --> 0.830013).  Saving model ...
Updating learning rate to 0.0004304672100000001
Epoch: 12 cost time: 0.7658734321594238
Epoch: 12, Steps: 46 | Train Loss: 0.7309725 Vali Loss: 0.8477003 Test Loss: 0.5381091
EarlyStopping counter: 1 out of 100
Updating learning rate to 0.0003874204890000001
Epoch: 13 cost time: 0.7713179588317871
Epoch: 13, Steps: 46 | Train Loss: 0.7228523 Vali Loss: 0.8483713 Test Loss: 0.5391902
EarlyStopping counter: 2 out of 100
Updating learning rate to 0.0003486784401000001
Epoch: 14 cost time: 0.6895191669464111
Epoch: 14, Steps: 46 | Train Loss: 0.7138521 Vali Loss: 0.8292224 Test Loss: 0.5381374
Validation loss decreased (0.830013 --> 0.829222).  Saving model ...
Updating learning rate to 0.0003138105960900001
Epoch: 15 cost time: 0.8165867328643799
Epoch: 15, Steps: 46 | Train Loss: 0.7061802 Vali Loss: 0.8203567 Test Loss: 0.5404132
Validation loss decreased (0.829222 --> 0.820357).  Saving model ...
Updating learning rate to 0.0002824295364810001
Epoch: 16 cost time: 0.9105710983276367
Epoch: 16, Steps: 46 | Train Loss: 0.7007250 Vali Loss: 0.8366219 Test Loss: 0.5411341
EarlyStopping counter: 1 out of 100
Updating learning rate to 0.0002541865828329001
Epoch: 17 cost time: 0.7937049865722656
Epoch: 17, Steps: 46 | Train Loss: 0.6954587 Vali Loss: 0.8520735 Test Loss: 0.5428652
EarlyStopping counter: 2 out of 100
Updating learning rate to 0.0002287679245496101
Epoch: 18 cost time: 0.8272433280944824
Epoch: 18, Steps: 46 | Train Loss: 0.6906872 Vali Loss: 0.8293489 Test Loss: 0.5439652
EarlyStopping counter: 3 out of 100
Updating learning rate to 0.0002058911320946491
Epoch: 19 cost time: 0.7132830619812012
Epoch: 19, Steps: 46 | Train Loss: 0.6844433 Vali Loss: 0.8245882 Test Loss: 0.5465512
EarlyStopping counter: 4 out of 100
Updating learning rate to 0.00018530201888518417
Epoch: 20 cost time: 0.7277853488922119
Epoch: 20, Steps: 46 | Train Loss: 0.6833413 Vali Loss: 0.8427351 Test Loss: 0.5464583
EarlyStopping counter: 5 out of 100
Updating learning rate to 0.00016677181699666576
Epoch: 21 cost time: 0.9901196956634521
Epoch: 21, Steps: 46 | Train Loss: 0.6797663 Vali Loss: 0.8174197 Test Loss: 0.5464448
Validation loss decreased (0.820357 --> 0.817420).  Saving model ...
Updating learning rate to 0.00015009463529699917
Epoch: 22 cost time: 0.7167143821716309
Epoch: 22, Steps: 46 | Train Loss: 0.6779558 Vali Loss: 0.8441488 Test Loss: 0.5471330
EarlyStopping counter: 1 out of 100
Updating learning rate to 0.0001350851717672993
Epoch: 23 cost time: 0.7654902935028076
Epoch: 23, Steps: 46 | Train Loss: 0.6752180 Vali Loss: 0.8414941 Test Loss: 0.5460406
EarlyStopping counter: 2 out of 100
Updating learning rate to 0.00012157665459056935
Epoch: 24 cost time: 0.6765964031219482
Epoch: 24, Steps: 46 | Train Loss: 0.6727352 Vali Loss: 0.8295965 Test Loss: 0.5458238
EarlyStopping counter: 3 out of 100
Updating learning rate to 0.00010941898913151242
Epoch: 25 cost time: 0.840364933013916
Epoch: 25, Steps: 46 | Train Loss: 0.6712377 Vali Loss: 0.8292662 Test Loss: 0.5463265
EarlyStopping counter: 4 out of 100
Updating learning rate to 9.847709021836118e-05
Epoch: 26 cost time: 0.7524611949920654
Epoch: 26, Steps: 46 | Train Loss: 0.6708027 Vali Loss: 0.8432747 Test Loss: 0.5466276
EarlyStopping counter: 5 out of 100
Updating learning rate to 8.862938119652506e-05
Epoch: 27 cost time: 0.8019042015075684
Epoch: 27, Steps: 46 | Train Loss: 0.6688899 Vali Loss: 0.8134599 Test Loss: 0.5453325
Validation loss decreased (0.817420 --> 0.813460).  Saving model ...
Updating learning rate to 7.976644307687256e-05
Epoch: 28 cost time: 0.7193634510040283
Epoch: 28, Steps: 46 | Train Loss: 0.6660102 Vali Loss: 0.8278856 Test Loss: 0.5471125
EarlyStopping counter: 1 out of 100
Updating learning rate to 7.17897987691853e-05
Epoch: 29 cost time: 0.8896329402923584
Epoch: 29, Steps: 46 | Train Loss: 0.6670157 Vali Loss: 0.8202329 Test Loss: 0.5452514
EarlyStopping counter: 2 out of 100
Updating learning rate to 6.461081889226677e-05
Epoch: 30 cost time: 0.9027614593505859
Epoch: 30, Steps: 46 | Train Loss: 0.6659838 Vali Loss: 0.8385676 Test Loss: 0.5456180
EarlyStopping counter: 3 out of 100
Updating learning rate to 5.8149737003040094e-05
>>>>>>>testing : crop_96_192_MLPAer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1591
find shape (1536, 192, 8) (1536, 192, 8)
mse:0.5453324317932129, mae:0.5571084022521973, nse:0.6576781272888184, mape:1.9604443311691284
