Args in experiment:
Namespace(random_seed=2025, is_training=1, model_id='ETTh1_96_336', model='MLPAer', data='ETTh1', root_path='./dataset/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, fc_dropout=0.05, head_dropout=0.7, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=5, learning_rate=0.0002, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, c_ff=14, t_ff=512, c_dropout=0.0, t_dropout=0.0, embed_dropout=0.0, head_type='prediction', usenorm=1, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh1_96_336_MLPAer_ETTh1_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2545
test 2545
Epoch: 1 cost time: 1.3723809719085693
Epoch: 1, Steps: 64 | Train Loss: 0.6708046 Vali Loss: 1.6644684 Test Loss: 0.7019805
Validation loss decreased (inf --> 1.664468).  Saving model ...
Updating learning rate to 0.0002
Epoch: 2 cost time: 1.0729694366455078
Epoch: 2, Steps: 64 | Train Loss: 0.5700713 Vali Loss: 1.3338045 Test Loss: 0.5033985
Validation loss decreased (1.664468 --> 1.333804).  Saving model ...
Updating learning rate to 0.0002
Epoch: 3 cost time: 1.1631183624267578
Epoch: 3, Steps: 64 | Train Loss: 0.5162393 Vali Loss: 1.3023794 Test Loss: 0.4864147
Validation loss decreased (1.333804 --> 1.302379).  Saving model ...
Updating learning rate to 0.0002
Epoch: 4 cost time: 1.1117370128631592
Epoch: 4, Steps: 64 | Train Loss: 0.5053020 Vali Loss: 1.2974805 Test Loss: 0.4816686
Validation loss decreased (1.302379 --> 1.297480).  Saving model ...
Updating learning rate to 0.00018
Epoch: 5 cost time: 1.1978240013122559
Epoch: 5, Steps: 64 | Train Loss: 0.4998134 Vali Loss: 1.2912881 Test Loss: 0.4752001
Validation loss decreased (1.297480 --> 1.291288).  Saving model ...
Updating learning rate to 0.000162
Epoch: 6 cost time: 1.576740026473999
Epoch: 6, Steps: 64 | Train Loss: 0.4959587 Vali Loss: 1.2929531 Test Loss: 0.4743654
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00014580000000000002
Epoch: 7 cost time: 1.1068305969238281
Epoch: 7, Steps: 64 | Train Loss: 0.4925840 Vali Loss: 1.2831870 Test Loss: 0.4686155
Validation loss decreased (1.291288 --> 1.283187).  Saving model ...
Updating learning rate to 0.00013122
Epoch: 8 cost time: 1.1675312519073486
Epoch: 8, Steps: 64 | Train Loss: 0.4895193 Vali Loss: 1.2861103 Test Loss: 0.4670059
EarlyStopping counter: 1 out of 5
Updating learning rate to 0.00011809800000000002
Epoch: 9 cost time: 1.1456270217895508
Epoch: 9, Steps: 64 | Train Loss: 0.4874654 Vali Loss: 1.2825409 Test Loss: 0.4653311
Validation loss decreased (1.283187 --> 1.282541).  Saving model ...
Updating learning rate to 0.00010628820000000001
Epoch: 10 cost time: 1.2403504848480225
Epoch: 10, Steps: 64 | Train Loss: 0.4854325 Vali Loss: 1.2796112 Test Loss: 0.4640568
Validation loss decreased (1.282541 --> 1.279611).  Saving model ...
Updating learning rate to 9.565938000000003e-05
Epoch: 11 cost time: 1.1986043453216553
Epoch: 11, Steps: 64 | Train Loss: 0.4833637 Vali Loss: 1.2828749 Test Loss: 0.4628396
EarlyStopping counter: 1 out of 5
Updating learning rate to 8.609344200000003e-05
Epoch: 12 cost time: 1.0969817638397217
Epoch: 12, Steps: 64 | Train Loss: 0.4818268 Vali Loss: 1.2766724 Test Loss: 0.4603618
Validation loss decreased (1.279611 --> 1.276672).  Saving model ...
Updating learning rate to 7.748409780000002e-05
Epoch: 13 cost time: 1.4126453399658203
Epoch: 13, Steps: 64 | Train Loss: 0.4805073 Vali Loss: 1.2789437 Test Loss: 0.4605199
EarlyStopping counter: 1 out of 5
Updating learning rate to 6.973568802000002e-05
Epoch: 14 cost time: 1.3180906772613525
Epoch: 14, Steps: 64 | Train Loss: 0.4791120 Vali Loss: 1.2840676 Test Loss: 0.4587847
EarlyStopping counter: 2 out of 5
Updating learning rate to 6.276211921800002e-05
Epoch: 15 cost time: 1.1716289520263672
Epoch: 15, Steps: 64 | Train Loss: 0.4784559 Vali Loss: 1.2831689 Test Loss: 0.4595796
EarlyStopping counter: 3 out of 5
Updating learning rate to 5.648590729620002e-05
Epoch: 16 cost time: 1.1010730266571045
Epoch: 16, Steps: 64 | Train Loss: 0.4773806 Vali Loss: 1.2730737 Test Loss: 0.4580147
Validation loss decreased (1.276672 --> 1.273074).  Saving model ...
Updating learning rate to 5.083731656658002e-05
Epoch: 17 cost time: 1.0689239501953125
Epoch: 17, Steps: 64 | Train Loss: 0.4764585 Vali Loss: 1.2703354 Test Loss: 0.4587000
Validation loss decreased (1.273074 --> 1.270335).  Saving model ...
Updating learning rate to 4.575358490992202e-05
Epoch: 18 cost time: 1.0596232414245605
Epoch: 18, Steps: 64 | Train Loss: 0.4755920 Vali Loss: 1.2796682 Test Loss: 0.4580538
EarlyStopping counter: 1 out of 5
Updating learning rate to 4.117822641892981e-05
Epoch: 19 cost time: 1.1289596557617188
Epoch: 19, Steps: 64 | Train Loss: 0.4752559 Vali Loss: 1.2755923 Test Loss: 0.4567234
EarlyStopping counter: 2 out of 5
Updating learning rate to 3.706040377703683e-05
Epoch: 20 cost time: 1.0899207592010498
Epoch: 20, Steps: 64 | Train Loss: 0.4746395 Vali Loss: 1.2767855 Test Loss: 0.4581263
EarlyStopping counter: 3 out of 5
Updating learning rate to 3.3354363399333154e-05
Epoch: 21 cost time: 1.1630940437316895
Epoch: 21, Steps: 64 | Train Loss: 0.4736792 Vali Loss: 1.2749776 Test Loss: 0.4564709
EarlyStopping counter: 4 out of 5
Updating learning rate to 3.0018927059399838e-05
Epoch: 22 cost time: 1.2580933570861816
Epoch: 22, Steps: 64 | Train Loss: 0.4731449 Vali Loss: 1.2832093 Test Loss: 0.4569620
EarlyStopping counter: 5 out of 5
Early stopping
>>>>>>>testing : ETTh1_96_336_MLPAer_ETTh1_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:0.4586999714374542, mae:0.4378586411476135, rse:0.6474271416664124
