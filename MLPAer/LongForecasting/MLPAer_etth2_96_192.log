Args in experiment:
Namespace(random_seed=2025, is_training=1, model_id='ETTh2_96_192', model='MLPAer', data='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, fc_dropout=0.05, head_dropout=0.4, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=30, batch_size=128, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type3', pct_start=0.3, use_amp=False, c_ff=7, t_ff=128, c_dropout=0.0, t_dropout=0.0, embed_dropout=0.0, head_type='prediction', usenorm=1, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : ETTh2_96_192_MLPAer_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
Epoch: 1 cost time: 1.208453893661499
Epoch: 1, Steps: 65 | Train Loss: 0.6169996 Vali Loss: 0.3228251 Test Loss: 0.4288763
Validation loss decreased (inf --> 0.322825).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9429411888122559
Epoch: 2, Steps: 65 | Train Loss: 0.5874355 Vali Loss: 0.2917028 Test Loss: 0.3951803
Validation loss decreased (0.322825 --> 0.291703).  Saving model ...
Updating learning rate to 0.0001
Epoch: 3 cost time: 1.032827377319336
Epoch: 3, Steps: 65 | Train Loss: 0.5573536 Vali Loss: 0.2817697 Test Loss: 0.3825990
Validation loss decreased (0.291703 --> 0.281770).  Saving model ...
Updating learning rate to 0.0001
Epoch: 4 cost time: 1.0111563205718994
Epoch: 4, Steps: 65 | Train Loss: 0.5464960 Vali Loss: 0.2770502 Test Loss: 0.3784038
Validation loss decreased (0.281770 --> 0.277050).  Saving model ...
Updating learning rate to 9e-05
Epoch: 5 cost time: 1.0133397579193115
Epoch: 5, Steps: 65 | Train Loss: 0.5414313 Vali Loss: 0.2763143 Test Loss: 0.3760132
Validation loss decreased (0.277050 --> 0.276314).  Saving model ...
Updating learning rate to 8.1e-05
Epoch: 6 cost time: 1.2589011192321777
Epoch: 6, Steps: 65 | Train Loss: 0.5377509 Vali Loss: 0.2749974 Test Loss: 0.3743009
Validation loss decreased (0.276314 --> 0.274997).  Saving model ...
Updating learning rate to 7.290000000000001e-05
Epoch: 7 cost time: 1.0807719230651855
Epoch: 7, Steps: 65 | Train Loss: 0.5347789 Vali Loss: 0.2746426 Test Loss: 0.3727524
Validation loss decreased (0.274997 --> 0.274643).  Saving model ...
Updating learning rate to 6.561e-05
Epoch: 8 cost time: 1.0732173919677734
Epoch: 8, Steps: 65 | Train Loss: 0.5340850 Vali Loss: 0.2741838 Test Loss: 0.3719234
Validation loss decreased (0.274643 --> 0.274184).  Saving model ...
Updating learning rate to 5.904900000000001e-05
Epoch: 9 cost time: 0.9985973834991455
Epoch: 9, Steps: 65 | Train Loss: 0.5313335 Vali Loss: 0.2748370 Test Loss: 0.3705361
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.3144100000000005e-05
Epoch: 10 cost time: 0.9663021564483643
Epoch: 10, Steps: 65 | Train Loss: 0.5288052 Vali Loss: 0.2740167 Test Loss: 0.3697956
Validation loss decreased (0.274184 --> 0.274017).  Saving model ...
Updating learning rate to 4.782969000000001e-05
Epoch: 11 cost time: 1.0071403980255127
Epoch: 11, Steps: 65 | Train Loss: 0.5263297 Vali Loss: 0.2741059 Test Loss: 0.3689510
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.304672100000001e-05
Epoch: 12 cost time: 0.9970853328704834
Epoch: 12, Steps: 65 | Train Loss: 0.5231092 Vali Loss: 0.2740376 Test Loss: 0.3680910
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.874204890000001e-05
Epoch: 13 cost time: 0.9271855354309082
Epoch: 13, Steps: 65 | Train Loss: 0.5226761 Vali Loss: 0.2738627 Test Loss: 0.3674218
Validation loss decreased (0.274017 --> 0.273863).  Saving model ...
Updating learning rate to 3.486784401000001e-05
Epoch: 14 cost time: 1.1076958179473877
Epoch: 14, Steps: 65 | Train Loss: 0.5216941 Vali Loss: 0.2739022 Test Loss: 0.3672720
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.138105960900001e-05
Epoch: 15 cost time: 0.9766075611114502
Epoch: 15, Steps: 65 | Train Loss: 0.5200737 Vali Loss: 0.2738520 Test Loss: 0.3665497
Validation loss decreased (0.273863 --> 0.273852).  Saving model ...
Updating learning rate to 2.824295364810001e-05
Epoch: 16 cost time: 1.0118260383605957
Epoch: 16, Steps: 65 | Train Loss: 0.5197158 Vali Loss: 0.2735184 Test Loss: 0.3666770
Validation loss decreased (0.273852 --> 0.273518).  Saving model ...
Updating learning rate to 2.541865828329001e-05
Epoch: 17 cost time: 0.9693593978881836
Epoch: 17, Steps: 65 | Train Loss: 0.5171199 Vali Loss: 0.2736208 Test Loss: 0.3664795
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.287679245496101e-05
Epoch: 18 cost time: 1.256622314453125
Epoch: 18, Steps: 65 | Train Loss: 0.5162267 Vali Loss: 0.2734459 Test Loss: 0.3662539
Validation loss decreased (0.273518 --> 0.273446).  Saving model ...
Updating learning rate to 2.0589113209464907e-05
Epoch: 19 cost time: 0.9469740390777588
Epoch: 19, Steps: 65 | Train Loss: 0.5174941 Vali Loss: 0.2737026 Test Loss: 0.3661768
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.8530201888518416e-05
Epoch: 20 cost time: 1.2145051956176758
Epoch: 20, Steps: 65 | Train Loss: 0.5169818 Vali Loss: 0.2734761 Test Loss: 0.3662545
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.6677181699666577e-05
Epoch: 21 cost time: 1.026149034500122
Epoch: 21, Steps: 65 | Train Loss: 0.5163362 Vali Loss: 0.2738020 Test Loss: 0.3660872
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_96_192_MLPAer_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
find shape (2688, 192, 7) (2688, 192, 7)
mse:0.36625388264656067, mae:0.38920921087265015, nse:0.7645030170679092, mape:1.5922670364379883
